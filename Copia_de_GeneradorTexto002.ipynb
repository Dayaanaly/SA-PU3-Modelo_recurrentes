{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dayaanaly/SA-PU3-Modelo_recurrentes/blob/Esteban/Copia_de_GeneradorTexto002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "tztS_qNRBKXC",
        "outputId": "47938753-2346-4926-b3e2-9a2b10cfabe0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-11a785ea3d8f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install tensorflow==2.0.1 numpy requests tqdm\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow==2.0.1 numpy requests tqdm\n",
        "fhdhe "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xbZYebauuqg"
      },
      "source": [
        "# preentrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9j1W4S6Mmoo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from string import punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtFxxNVZMsrQ",
        "outputId": "0031b5f7-0397-4379-cdef-1aa2ca8ca208"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "465593"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "import requests\n",
        "content = requests.get(\"https://www.gutenberg.org/cache/epub/42324/pg42324.txt\").text\n",
        "open(\"data\\Frankeinstein.txt\", \"w\", encoding=\"utf-8\").write(content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXiMBKL5NvjV"
      },
      "outputs": [],
      "source": [
        "sequence_length = 100\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 30\n",
        "# dataset file path\n",
        "FILE_PATH = \"data\\Frankeinstein.txt\"\n",
        "BASENAME = os.path.basename(FILE_PATH)\n",
        "# read the data\n",
        "text = open(FILE_PATH, encoding=\"utf-8\").read()\n",
        "# remove caps, comment this code if you want uppercase characters as well\n",
        "#text = text.lower()\n",
        "# remove punctuation\n",
        "text = text.translate(str.maketrans(\"\", \"\", punctuation))\n",
        "#text = text.ascii_letters + \" .,;'\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y63bzqnANzvr",
        "outputId": "9a118858-f077-4c95-ed86-f3a3ad05b66a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_chars: \n",
            " 0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzæèéêô﻿\n",
            "Number of characters: 443896\n",
            "Number of unique characters: 70\n"
          ]
        }
      ],
      "source": [
        "# print some stats\n",
        "n_chars = len(text)\n",
        "vocab = ''.join(sorted(set(text)))\n",
        "print(\"unique_chars:\", vocab)\n",
        "n_unique_chars = len(vocab)\n",
        "print(\"Number of characters:\", n_chars)\n",
        "print(\"Number of unique characters:\", n_unique_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xct5oeDIN9lT"
      },
      "outputs": [],
      "source": [
        "# dictionary that converts characters to integers\n",
        "char2int = {c: i for i, c in enumerate(vocab)}\n",
        "# dictionary that converts integers to characters\n",
        "int2char = {i: c for i, c in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbMCj4LJOBZb"
      },
      "outputs": [],
      "source": [
        "# save these dictionaries for later generation\n",
        "pickle.dump(char2int, open(f\"{BASENAME}-char2int.pickle\", \"wb\"))\n",
        "pickle.dump(int2char, open(f\"{BASENAME}-int2char.pickle\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2upau04UOEny"
      },
      "outputs": [],
      "source": [
        "# convert all text into integers\n",
        "encoded_text = np.array([char2int[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCqkGliHOG3t"
      },
      "outputs": [],
      "source": [
        "# construct tf.data.Dataset object\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rdh6ev9OGBi",
        "outputId": "07752d59-20a7-420b-df9e-c4bbcc522974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69 ﻿\n",
            "31 T\n",
            "45 h\n",
            "42 e\n",
            "1  \n",
            "27 P\n",
            "55 r\n",
            "52 o\n"
          ]
        }
      ],
      "source": [
        "# print first 5 characters\n",
        "for char in char_dataset.take(8):\n",
        "    print(char.numpy(), int2char[char.numpy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hENFjopbOkL6",
        "outputId": "d418c1db-b28a-49ca-e4e8-be7ef9252582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg EBook of Frankenstein by Mary W Shelley\n",
            "\n",
            "This eBook is for the use of anyone anywhere at no cost and with\n",
            "almost no restrictions whatsoever  You may copy it give it away or\n",
            "reuse\n",
            " it under the terms of the Project Gutenberg License included\n",
            "with this eBook or online at wwwgutenbergorg\n",
            "\n",
            "\n",
            "Title Frankenstein\n",
            "       or The Modern Prometheus\n",
            "\n",
            "Author Mary W Shelley\n",
            "\n",
            "Release Date Marc\n"
          ]
        }
      ],
      "source": [
        "# build sequences by batching\n",
        "sequences = char_dataset.batch(2*sequence_length + 1, drop_remainder=True)\n",
        "\n",
        "# print sequences\n",
        "for sequence in sequences.take(2):\n",
        "    print(''.join([int2char[i] for i in sequence.numpy()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhdVPPVdOxVp"
      },
      "outputs": [],
      "source": [
        "def split_sample(sample):\n",
        "    # example :\n",
        "    # sequence_length is 10\n",
        "    # sample is \"python is a great pro\" (21 length)\n",
        "    # ds will equal to ('python is ', 'a') encoded as integers\n",
        "    ds = tf.data.Dataset.from_tensors((sample[:sequence_length], sample[sequence_length]))\n",
        "    for i in range(1, (len(sample)-1) // 2):\n",
        "        # first (input_, target) will be ('ython is a', ' ')\n",
        "        # second (input_, target) will be ('thon is a ', 'g')\n",
        "        # third (input_, target) will be ('hon is a g', 'r')\n",
        "        # and so on\n",
        "        input_ = sample[i: i+sequence_length]\n",
        "        target = sample[i+sequence_length]\n",
        "        # extend the dataset with these samples by concatenate() method\n",
        "        other_ds = tf.data.Dataset.from_tensors((input_, target))\n",
        "        ds = ds.concatenate(other_ds)\n",
        "    return ds\n",
        "\n",
        "# prepare inputs and targets\n",
        "dataset = sequences.flat_map(split_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKz0ohvjO3KJ"
      },
      "outputs": [],
      "source": [
        "def one_hot_samples(input_, target):\n",
        "    # onehot encode the inputs and the targets\n",
        "    # Example:\n",
        "    # if character 'd' is encoded as 3 and n_unique_chars = 5\n",
        "    # result should be the vector: [0, 0, 0, 1, 0], since 'd' is the 4th character\n",
        "    return tf.one_hot(input_, n_unique_chars), tf.one_hot(target, n_unique_chars)\n",
        "\n",
        "dataset = dataset.map(one_hot_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cevB1cTGO7BG",
        "outputId": "8b300ba3-0968-4a2e-ef7d-5532a50b7552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: ﻿The Project Gutenberg EBook of Frankenstein by Mary W Shelley\n",
            "\n",
            "This eBook is for the use of anyone \n",
            "Target: a\n",
            "Input shape: (100, 70)\n",
            "Target shape: (70,)\n",
            "================================================== \n",
            "\n",
            "Input: The Project Gutenberg EBook of Frankenstein by Mary W Shelley\n",
            "\n",
            "This eBook is for the use of anyone a\n",
            "Target: n\n",
            "Input shape: (100, 70)\n",
            "Target shape: (70,)\n",
            "================================================== \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# print first 2 samples\n",
        "for element in dataset.take(2):\n",
        "    print(\"Input:\", ''.join([int2char[np.argmax(char_vector)] for char_vector in element[0].numpy()]))\n",
        "    print(\"Target:\", int2char[np.argmax(element[1].numpy())])\n",
        "    print(\"Input shape:\", element[0].shape)\n",
        "    print(\"Target shape:\", element[1].shape)\n",
        "    print(\"=\"*50, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu-bWQtlPE7a"
      },
      "outputs": [],
      "source": [
        "# repeat, shuffle and batch the dataset\n",
        "ds = dataset.repeat().shuffle(1024).batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5WaZLULUKoa",
        "outputId": "935aa573-51dd-427d-827d-fa8ab267364e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy==1.18.5 in /usr/local/lib/python3.7/dist-packages (1.18.5)\n"
          ]
        }
      ],
      "source": [
        "pip install -U numpy==1.18.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vzqCT9iT-OB"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    LSTM(256, input_shape=(sequence_length, n_unique_chars), return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(256),\n",
        "    Dense(n_unique_chars, activation=\"softmax\"),])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpA7GyaTggNf",
        "outputId": "eb99bb8b-3f13-445b-82c9-4722acae7af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 100, 256)          334848    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100, 256)          0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 70)                17990     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 878,150\n",
            "Trainable params: 878,150\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# define the model path\n",
        "model_weights_path = f\"results/{BASENAME}-{sequence_length}.h5\"\n",
        "model.summary()\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKxo05LXu0JL"
      },
      "source": [
        "# entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFYNpj_Kg_9O",
        "outputId": "486717e2-8c73-42e6-ce7a-2e543c35979e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1733/1733 [==============================] - 132s 72ms/step - loss: 2.6528 - accuracy: 0.2509\n",
            "Epoch 2/30\n",
            "1733/1733 [==============================] - 124s 71ms/step - loss: 2.2179 - accuracy: 0.3525\n",
            "Epoch 3/30\n",
            "1733/1733 [==============================] - 124s 71ms/step - loss: 1.8687 - accuracy: 0.4404\n",
            "Epoch 4/30\n",
            "1733/1733 [==============================] - 124s 72ms/step - loss: 1.6745 - accuracy: 0.4936\n",
            "Epoch 5/30\n",
            "1733/1733 [==============================] - 124s 71ms/step - loss: 1.5501 - accuracy: 0.5318\n",
            "Epoch 6/30\n",
            "1733/1733 [==============================] - 124s 72ms/step - loss: 1.4651 - accuracy: 0.5568\n",
            "Epoch 7/30\n",
            "1733/1733 [==============================] - 124s 72ms/step - loss: 1.4032 - accuracy: 0.5747\n",
            "Epoch 8/30\n",
            "1733/1733 [==============================] - 125s 72ms/step - loss: 1.3560 - accuracy: 0.5873\n",
            "Epoch 9/30\n",
            "1733/1733 [==============================] - 125s 72ms/step - loss: 1.3169 - accuracy: 0.5976\n",
            "Epoch 10/30\n",
            "1733/1733 [==============================] - 125s 72ms/step - loss: 1.2836 - accuracy: 0.6067\n",
            "Epoch 11/30\n",
            "1733/1733 [==============================] - 125s 72ms/step - loss: 1.2552 - accuracy: 0.6145\n",
            "Epoch 12/30\n",
            "1733/1733 [==============================] - 125s 72ms/step - loss: 1.2289 - accuracy: 0.6215\n",
            "Epoch 13/30\n",
            "1733/1733 [==============================] - 125s 72ms/step - loss: 1.2053 - accuracy: 0.6275\n",
            "Epoch 14/30\n",
            "1733/1733 [==============================] - 125s 72ms/step - loss: 1.1843 - accuracy: 0.6332\n",
            "Epoch 15/30\n",
            "1733/1733 [==============================] - 125s 72ms/step - loss: 1.1630 - accuracy: 0.6392\n",
            "Epoch 16/30\n",
            "1733/1733 [==============================] - 126s 72ms/step - loss: 1.1457 - accuracy: 0.6438\n",
            "Epoch 17/30\n",
            "1733/1733 [==============================] - 125s 72ms/step - loss: 1.1265 - accuracy: 0.6492\n",
            "Epoch 18/30\n",
            " 599/1733 [=========>....................] - ETA: 1:21 - loss: 1.1090 - accuracy: 0.6535"
          ]
        }
      ],
      "source": [
        "# make results folder if does not exist yet\n",
        "if not os.path.isdir(\"results\"):\n",
        "    os.mkdir(\"results\")\n",
        "# train the model\n",
        "model.fit(ds, steps_per_epoch=(len(encoded_text) - sequence_length) // BATCH_SIZE, epochs=EPOCHS)\n",
        "# save the model\n",
        "model.save(model_weights_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sUAg5nQiLRU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import tqdm\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Activation\n",
        "import os\n",
        "\n",
        "sequence_length = 100\n",
        "# dataset file path\n",
        "FILE_PATH = \"/content/data\\Frankeinstein.txt\"\n",
        "# FILE_PATH = \"data/python_code.py\"\n",
        "BASENAME = os.path.basename(FILE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VumSBrT8iN4U"
      },
      "outputs": [],
      "source": [
        "seed = \"disconfort\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Fap-kekiPNM"
      },
      "outputs": [],
      "source": [
        "# load vocab dictionaries\n",
        "char2int = pickle.load(open(f\"{BASENAME}-char2int.pickle\", \"rb\"))\n",
        "int2char = pickle.load(open(f\"{BASENAME}-int2char.pickle\", \"rb\"))\n",
        "vocab_size = len(char2int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpcmATuBi22U"
      },
      "outputs": [],
      "source": [
        "# building the model\n",
        "model = Sequential([\n",
        "    LSTM(256, input_shape=(sequence_length, vocab_size), return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(256),\n",
        "    Dense(vocab_size, activation=\"softmax\"),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEip-OPFi5De"
      },
      "outputs": [],
      "source": [
        "# load the optimal weights\n",
        "model.load_weights(f\"results/{BASENAME}-{sequence_length}.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYZBl4TkjNpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c61b0ea-3000-4886-ebac-effdfe17c194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating text: 100%|██████████| 5000/5000 [03:49<00:00, 21.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed: disconfort\n",
            "Generated text:\n",
            "\n",
            "\n",
            "It is concerning\n",
            "to me I should\n",
            "having last\n",
            "elevating a\n",
            "very diver\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "because the\n",
            "search for\n",
            "ever than his\n",
            "friends which\n",
            "provided his\n",
            "encounted and\n",
            "the anguared\n",
            "by the more\n",
            "smiled her\n",
            "could have\n",
            "been that a\n",
            "shap of her\n",
            "countenance\n",
            "and he felt\n",
            "becau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "s = seed\n",
        "n_chars = 5000\n",
        "# generate 400 characters\n",
        "generated = \"\"\n",
        "for i in tqdm.tqdm(range(n_chars), \"Generating text\"):\n",
        "    # make the input sequence\n",
        "    X = np.zeros((1, sequence_length, vocab_size))\n",
        "    for t, char in enumerate(seed):\n",
        "        X[0, (sequence_length - len(seed)) + t, char2int[char]] = 1\n",
        "    # predict the next character\n",
        "    predicted = model.predict(X, verbose=0)[0]\n",
        "    # converting the vector to an integer\n",
        "    next_index = np.argmax(predicted)\n",
        "    # converting the integer to a character\n",
        "    next_char = int2char[next_index]\n",
        "    # add the character to results\n",
        "    generated += next_char\n",
        "    # shift seed and the predicted character\n",
        "    seed = seed[1:] + next_char\n",
        "\n",
        "print(\"Seed:\", s)\n",
        "print(\"Generated text:\")\n",
        "print(generated)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_xbZYebauuqg"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}